{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbtmi26eYfaK"
      },
      "source": [
        "#**Final Project - Basics of deep learning**\n",
        "\n",
        "#**Name and ID:**\n",
        "\n",
        "Student 1: Ilan Brilovitch 322525072\n",
        "\n",
        "\n",
        "Student 2: Chen Shalev 313584906\n",
        "\n",
        "\n",
        "Student 3: Lin Tibi 318232139\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl-RKCAWd25V"
      },
      "source": [
        "#**Import Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhOJs5szYonv"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "import re\n",
        "import math\n",
        "import functools\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.utils import load_img\n",
        "from keras.preprocessing import image\n",
        "from sklearn import metrics\n",
        "from keras import backend as K\n",
        "from google.colab import drive\n",
        "from sklearn.utils import shuffle\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models, layers, optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.models import Sequential, load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLihk6xid-6e"
      },
      "source": [
        "#**Load Dataset**\n",
        "\n",
        "Chest X-Ray Images (Pneumonia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz2Sb2h4ZjMW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Your Kaggle credentials\n",
        "kaggle_credentials = {\n",
        "    \"username\": \"ilanbrilovitch\",\n",
        "    \"key\": \"0f1ee3dac62e187e2b0fbd8290e20b79\"\n",
        "}\n",
        "\n",
        "# Create the Kaggle directory if it doesn't exist\n",
        "kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "# Write the Kaggle credentials to the kaggle.json file\n",
        "kaggle_json_path = os.path.join(kaggle_dir, \"kaggle.json\")\n",
        "with open(kaggle_json_path, \"w\") as kaggle_file:\n",
        "    json.dump(kaggle_credentials, kaggle_file)\n",
        "\n",
        "# Set the appropriate permissions\n",
        "os.chmod(kaggle_json_path, 0o600)\n",
        "\n",
        "print(\"Kaggle credentials set successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCY30LGIZpD6"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "\n",
        "!unzip -q chest-xray-pneumonia.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIe0yiN2kfOp"
      },
      "source": [
        "#**Loading Weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6CAnR10kgmQ"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "\n",
        "json_url = 'https://drive.google.com/uc?id=1i32WYld7dv9JRH-11x-9nix5T6N7G8Uo'\n",
        "json_output = 'history_a1.json'\n",
        "\n",
        "gdown.download(json_url, json_output, quiet=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "h5_url = 'https://drive.google.com/uc?id=1QyLGDhNkw-fQT64GVi4JCp08ga_dnyFu'    # Modified URL to get the file directly, this file is binary\n",
        "h5_output = 'model_a1.h5'\n",
        "\n",
        "gdown.download(h5_url, h5_output, quiet=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1IYEYgoOvQqNxwL3FlWF4gVEAv2-j08cf'\n",
        "output = 'history_a2.json'\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1QcvHU5HS-AvpR0ewhbPt9A1gACD66qKA'  # Modified URL to get the file directly, this file is binary\n",
        "output = 'model_a2.h5'\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Download the JSON file\n",
        "url_json = 'https://drive.google.com/uc?id=190g5K5ZiDa4Zez7SPTqTRqoFTpNtcrlw'\n",
        "output_json = 'history_d.json'\n",
        "\n",
        "gdown.download(url_json, output_json, quiet=False)\n",
        "\n",
        "\n",
        "# Download the binary file (assuming it's a TensorFlow model in HDF5 format)\n",
        "url_h5 = 'https://drive.google.com/uc?id=1c-dwW-5OuMl63HLcA2vNTwOC4CXpRYKR'\n",
        "output_h5 = 'model_d.h5'\n",
        "\n",
        "gdown.download(url_h5, output_h5, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxjPU5EbH8JH"
      },
      "source": [
        "#**Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7faS9j3_WNCg"
      },
      "source": [
        "#**Question 1.a - Classification Healthy / Sick**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the saved model\n",
        "saved_model = load_model('/content/model_a1.h5')\n",
        "\n",
        "# Load the training history\n",
        "with open('/content/history_a1.json') as json_file:\n",
        "    loaded_history = json.load(json_file)\n",
        "\n",
        "# Function to display the file upload widget\n",
        "def upload_file():\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())[0]  # Return the first uploaded file path\n",
        "\n",
        "def classify_image(image_path, model):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    classes = ['Healthy', 'Sick']\n",
        "\n",
        "    result = {\n",
        "        \"class\": classes[np.argmax(prediction)],\n",
        "        \"confidence\": f\"{np.max(prediction) * 100:.2f}%\"\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "# Get the file path from the user\n",
        "new_image_path = upload_file()\n",
        "\n",
        "# Classify the uploaded image\n",
        "result = classify_image(new_image_path, saved_model)\n",
        "print(f'The image is classified as {result[\"class\"]} with confidence {result[\"confidence\"]}')\n"
      ],
      "metadata": {
        "id": "0H3b5ewzcAiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il0-dhVjR921"
      },
      "source": [
        "#**Question 1.b- Classification healthy / viral pneumonia / bacterial pneumonia**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Load the saved model\n",
        "saved_model = load_model('/content/model_a2.h5')\n",
        "\n",
        "# Load the training history\n",
        "with open('/content/history_a2.json') as json_file:\n",
        "    loaded_history = json.load(json_file)\n",
        "\n",
        "# Function to display the file upload widget\n",
        "def upload_file():\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())[0]  # Return the first uploaded file path\n",
        "\n",
        "# Function to classify the uploaded image\n",
        "def classify_image(image_path, model):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    classes = ['Bacterial Pneumonia', 'Healthy', 'Viral Pneumonia']\n",
        "    result = {\n",
        "        \"class\": classes[np.argmax(prediction)],\n",
        "        \"confidence\": f\"{np.max(prediction) * 100:.2f}%\"\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "# Get the file path from the user\n",
        "new_image_path = upload_file()\n",
        "\n",
        "# Classify the uploaded image\n",
        "result = classify_image(new_image_path, saved_model)\n",
        "print(f'The image is classified as {result[\"class\"]} with confidence {result[\"confidence\"]}')\n"
      ],
      "metadata": {
        "id": "Hi5Riwenc5DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fkyLGVjtpbb"
      },
      "source": [
        "#**Question 2-  K-Nearest Neighbors (KNN)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**KNN for 1.a**"
      ],
      "metadata": {
        "id": "jYscQ9rEf0sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.models import load_model, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Load the saved model\n",
        "saved_model = load_model('/content/model_a1.h5')\n",
        "\n",
        "# Extract the embedding layer from the model\n",
        "embedding_layer_model = Model(inputs=saved_model.input, outputs=saved_model.get_layer('dense_11').output)\n",
        "\n",
        "# Function to display the file upload widget\n",
        "def upload_file():\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())[0]  # Return the first uploaded file path\n",
        "\n",
        "# Function to extract features from images\n",
        "def extract_features(directory, model):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for class_folder in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_folder)\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = image.load_img(img_path, target_size=(224, 224))\n",
        "            img_array = image.img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            img_array /= 255.0\n",
        "            feature = model.predict(img_array)\n",
        "            features.append(feature.flatten())\n",
        "            labels.append(class_folder)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Get the file path from the user\n",
        "new_image_path = upload_file()\n",
        "\n",
        "# Extract features from training data\n",
        "train_dir = '/content/chest_xray/train'\n",
        "train_features, train_labels = extract_features(train_dir, embedding_layer_model)\n",
        "\n",
        "# Split the data for KNN training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate KNN classifier on test data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy of KNN classifier: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Visualize classes using T-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_result = tsne.fit_transform(train_features)\n",
        "\n",
        "# Plot T-SNE results\n",
        "plt.figure(figsize=(10, 8))\n",
        "for label in np.unique(train_labels):\n",
        "    indices = np.where(train_labels == label)\n",
        "    plt.scatter(tsne_result[indices, 0], tsne_result[indices, 1], label=label, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title('T-SNE Visualization of Classes')\n",
        "plt.show()\n",
        "\n",
        "# Function to classify image using KNN\n",
        "def classify_image_knn(image_path, knn_model, embedding_model):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    feature = embedding_model.predict(img_array).flatten()\n",
        "    prediction = knn_model.predict([feature])\n",
        "\n",
        "    return prediction[0]\n",
        "\n",
        "# Convert the label to uppercase to match the labels in the training data\n",
        "knn_prediction = classify_image_knn(new_image_path, knn_classifier, embedding_layer_model).upper()\n",
        "\n",
        "# Print the department name instead of a department number\n",
        "department_names = {'NORMAL': 'Healthy ', 'PNEUMONIA': 'Sick '}\n",
        "print(f'The image is classified as {department_names[knn_prediction]} using KNN classifier')\n",
        "print(f'Accuracy of KNN classifier: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "hsoadKOYw78e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXkWQyA2K0CO"
      },
      "source": [
        "#**KNN for 1.b**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "# train\n",
        "# Organize pneumonia data into viral and bacterial subdirectories\n",
        "pneumonia_dir = '/content/chest_xray/train/PNEUMONIA'\n",
        "viral_pneumonia_dir = '/content/chest_xray/train/Viral_Pneumonia'\n",
        "bacterial_pneumonia_dir = '/content/chest_xray/train/Bacterial_Pneumonia'\n",
        "\n",
        "os.makedirs(viral_pneumonia_dir, exist_ok=True)\n",
        "os.makedirs(bacterial_pneumonia_dir, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(pneumonia_dir):\n",
        "    if 'virus' in filename:\n",
        "        os.rename(os.path.join(pneumonia_dir, filename), os.path.join(viral_pneumonia_dir, filename))\n",
        "    elif 'bacteria' in filename:\n",
        "        os.rename(os.path.join(pneumonia_dir, filename), os.path.join(bacterial_pneumonia_dir, filename))\n",
        "\n",
        "# מחיקת התיקייה המקורית PNEUMONIA\n",
        "shutil.rmtree(pneumonia_dir)\n",
        "\n",
        "\n",
        "# Load the saved model\n",
        "saved_model = load_model('/content/model_a2.h5')\n",
        "\n",
        "# Extract the embedding layer from the model\n",
        "embedding_layer_model = Model(inputs=saved_model.input, outputs=saved_model.get_layer('dense_5').output)\n",
        "\n",
        "\n",
        "# Function to extract features from images\n",
        "def extract_features(directory, model):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for class_folder in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_folder)\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = image.load_img(img_path, target_size=(224, 224))\n",
        "            img_array = image.img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            img_array /= 255.0\n",
        "            feature = model.predict(img_array)\n",
        "            features.append(feature.flatten())\n",
        "            labels.append(class_folder)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Function to upload an image from user's computer\n",
        "def upload_image():\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        return fn\n",
        "\n",
        "# Example - upload image\n",
        "uploaded_image_path = upload_image()\n",
        "\n",
        "# Define data directories\n",
        "train_dir = '/content/chest_xray/train'\n",
        "val_dir = '/content/chest_xray/val'\n",
        "test_dir = '/content/chest_xray/test'\n",
        "\n",
        "# Extract features from training data\n",
        "train_features, train_labels = extract_features(train_dir, embedding_layer_model)\n",
        "\n",
        "# Split the data for KNN training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate KNN classifier on test data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy of KNN classifier: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Visualize classes using T-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_result = tsne.fit_transform(train_features)\n",
        "\n",
        "# Plot T-SNE results\n",
        "plt.figure(figsize=(10, 8))\n",
        "for label in np.unique(train_labels):\n",
        "    indices = np.where(train_labels == label)\n",
        "    plt.scatter(tsne_result[indices, 0], tsne_result[indices, 1], label=label, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title('T-SNE Visualization of Classes')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to classify image using KNN\n",
        "def classify_image_knn(image_path, knn_classifier, embedding_model):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    feature = embedding_model.predict(img_array).flatten()\n",
        "    prediction = knn_classifier.predict([feature])\n",
        "\n",
        "    return prediction[0]\n",
        "\n",
        "# Example 2 - put your image\n",
        "new_image_path = uploaded_image_path  # Provide the path to your image\n",
        "knn_prediction = classify_image_knn(new_image_path, knn_classifier, embedding_layer_model)\n",
        "# Print the department name instead of a department number\n",
        "department_names = {'Bacterial_Pneumonia': 'Bacterial Pneumonia', 'NORMAL': 'Healthy ', 'Viral_Pneumonia': 'Viral Pneumonia'}\n",
        "print(f'The image is classified as {department_names[knn_prediction]} using KNN classifier')\n",
        "print(f'Accuracy of KNN classifier: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "YuHnAWnYxgzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 4- Anomaly Detection**"
      ],
      "metadata": {
        "id": "Rj35jIyAGm7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the saved model\n",
        "saved_model = load_model('/content/model_d.h5')\n",
        "\n",
        "# Load the training history\n",
        "with open('/content/history_d.json') as json_file:\n",
        "    loaded_history = json.load(json_file)\n",
        "\n",
        "# Function to display the file upload widget\n",
        "def upload_file():\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())[0]  # Return the first uploaded file path\n",
        "\n",
        "# Get the file path from the user\n",
        "image_path = upload_file()\n",
        "\n",
        "# Load and preprocess the uploaded image for anomaly detection\n",
        "img = load_img(image_path, target_size=(224, 224))\n",
        "img_array = img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # rescale to [0,1]\n",
        "\n",
        "# Predict and calculate reconstruction errors\n",
        "anomaly_predictions = saved_model.predict(img_array, verbose=1)\n",
        "anomaly_errors = np.mean(np.square(img_array - anomaly_predictions))\n",
        "\n",
        "# Set a threshold for anomaly detection (you may need to adjust this based on your data)\n",
        "threshold = 0.0254\n",
        "\n",
        "# Classify image as healthy or sick based on the threshold\n",
        "anomaly_label = 'healthy' if anomaly_errors < threshold else 'sick'\n",
        "\n",
        "print(\"Anomaly Label:\", anomaly_label)\n",
        "print(\"Anomaly Errors:\", anomaly_errors)\n"
      ],
      "metadata": {
        "id": "vTsD8QxHaHou"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}